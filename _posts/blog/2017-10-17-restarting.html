---
layout: blog
title:  "Restarting"
date:   2017-10-21
category: blog
header-title: blog
---

Graduate school applications loom, so it is time to dust off this old website.
<br />
<br />
<img src="{{ site.baseurl }}/resources/2017-10-17-restarting/blog/mgh_id.png" alt=""{{ site.baseurl }}/>
<br />
<br />
I've spent the last year and a half working at the Quantiative Tumor Imaging Lab (<a href='https://www.martinos.org/lab/qtim'>QTIM</a>) / <a href='https://www.nmr.mgh.harvard.edu/machinelearning'>Center for Machine Learning</a> at Mass General Hospital's Martinos Center. In my first few months of working as research assistant, I spent time writing software to improve upon widely-used biological models in brain cancer imaging, creating statistics and visualizations for ongoing cohort studies, and tooling around with random forests and image-feature extraction for prediction projects. From the first month, the idea of "deep learning" had been mentioned as a distant but potentially fearsome storm, but no one really had a handle of its full capabilities. I was told to poke around in Tensorflow, but it seemed hopelessly abstract, and it was hard to get a handle on how it could usefully apply to our research. I went back to tinkering with biological models and texture features absent deep learning, and stayed there for six months.
<br />
<br />
In retrospect, that time seems insane. An assignment to replicate the work of <a href='https://github.com/Kamnitsask/deepmedic'>DeepMedic</a>, a popular and well-documented brain tumor segmentation package using convolutional neural networks, sparked an irreversible transformation of our lab into a deep learning lab, and myself into a deep learning researcher. Successfully replicating DeepMedic gave way to trying to top its accuracy at this year's brain tumor segmentation competition (<a href='http://braintumorsegmentation.org/'>"BRATS"</a>). Myself, as well as our lab's graduate student and postdoc, took to somewhat obsessively discussing filter sizes, layer depths, residual connections, and pseudo-probabilities for about two months in an attempt to get a competing package running. We ended up not coming in BRATS top four entrants, but we came close, and it turned out not to really matter; the lack of diversity in this year's competition entries showed that brain tumor segmentation may be, for practical purposes, a solved problem. What ended up being more important was the knowledge gained during the process, the seeds for dozens of future projects, and the skeleton of a medical-imaging/deep-learning package that we would endlessly re-use and later flesh out into "<a href='https://github.com/QTIM-Lab/DeepNeuro'>DeepNeuro</a>", our up-and-coming marquee python package. The competition ended, but we started deep learning, and we weren't going to stop.
<br />
<br />
I'll be going into more detail about the specific projects and software packages that resulted from that winter and summer in other posts on the site. There will be a million-and-one supervised learning tasks detailed there, including 3D image segmentation, 3D images super-resolution, missing scan generation, and survival prediction tasks. There will also be my attempts to create software packages for many of these projects to reduce the barrier between deep learning and the clinician (or perhaps their research technician). Finally, there will be some visualizations into my attempts to understand what knowledge is being encoded in the neural networks we're training, both at the surface layers (edges, corners, intensity, shape) and at the lowest level of abstraction (tumor, normal tissue, artery, cerebellum).
<br />
<br />
There's a lot of work left to be done, and a lot of interesting projects yet to be started. Medical imaging researchers seem to have only recently "discovered" a world of deep learning that normal computer vision scientists had known about for years, with the result being that the forefront of deep learning in medical imaging lags at least months behind the forefront of deep learning more generally. I'm going to be working on some projects with neural networks for 4D (3D + time) imaging, and even more interestingly (to me), with reinforcement learning in 3D images. I'm also going to keep pushing the front of saliency in neural networks for medical imaging, both because it's just super cool, and because it seems like most clinicians will be skeptical of a method until they can find a semantic representation for what, exactly, it's doing.
<br />
<br />
If you have any questions about any of that, send me an email at andrew underscore beers at alumni dot brown dot edu!